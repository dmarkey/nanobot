<div align="center">
  <img src="nanobot_logo.png" alt="nanobot" width="500">
  <h1>nanobot: Ultra-Lightweight Personal AI Assistant</h1>
  <p>
    <a href="https://pypi.org/project/nanobot-ai/"><img src="https://img.shields.io/pypi/v/nanobot-ai" alt="PyPI"></a>
    <a href="https://pepy.tech/project/nanobot-ai"><img src="https://static.pepy.tech/badge/nanobot-ai" alt="Downloads"></a>
    <img src="https://img.shields.io/badge/python-‚â•3.11-blue" alt="Python">
    <img src="https://img.shields.io/badge/license-MIT-green" alt="License">
    <a href="./COMMUNICATION.md"><img src="https://img.shields.io/badge/Feishu-Group-E9DBFC?style=flat&logo=feishu&logoColor=white" alt="Feishu"></a>
    <a href="./COMMUNICATION.md"><img src="https://img.shields.io/badge/WeChat-Group-C5EAB4?style=flat&logo=wechat&logoColor=white" alt="WeChat"></a>
    <a href="https://discord.gg/MnCvHqpUGB"><img src="https://img.shields.io/badge/Discord-Community-5865F2?style=flat&logo=discord&logoColor=white" alt="Discord"></a>
  </p>
</div>

üêà **nanobot** is an **ultra-lightweight** personal AI assistant inspired by [OpenClaw](https://github.com/openclaw/openclaw) 

‚ö°Ô∏è Delivers core agent functionality in just **~4,000** lines of code ‚Äî **99% smaller** than Clawdbot's 430k+ lines.

üìè Real-time line count: **3,897 lines** (run `bash core_agent_lines.sh` to verify anytime)

## üì¢ News

- **2026-02-21** üéâ Released **v0.1.4.post1** ‚Äî new providers, media support across channels, and major stability improvements. See [release notes](https://github.com/HKUDS/nanobot/releases/tag/v0.1.4.post1) for details.
- **2026-02-20** üê¶ Feishu now receives multimodal files from users. More reliable memory under the hood.
- **2026-02-19** ‚ú® Slack now sends files, Discord splits long messages, and subagents work in CLI mode.
- **2026-02-18** ‚ö°Ô∏è nanobot now supports VolcEngine, MCP custom auth headers, and Anthropic prompt caching.
- **2026-02-17** üéâ Released **v0.1.4** ‚Äî MCP support, progress streaming, new providers, and multiple channel improvements. Please see [release notes](https://github.com/HKUDS/nanobot/releases/tag/v0.1.4) for details.
- **2026-02-16** ü¶û nanobot now integrates a [ClawHub](https://clawhub.ai) skill ‚Äî search and install public agent skills.
- **2026-02-15** üîë nanobot now supports OpenAI Codex provider with OAuth login support.
- **2026-02-14** üîå nanobot now supports MCP! See [MCP section](#mcp-model-context-protocol) for details.
- **2026-02-13** üéâ Released **v0.1.3.post7** ‚Äî includes security hardening and multiple improvements. **Please upgrade to the latest version to address security issues**. See [release notes](https://github.com/HKUDS/nanobot/releases/tag/v0.1.3.post7) for more details.
- **2026-02-12** üß† Redesigned memory system ‚Äî Less code, more reliable. Join the [discussion](https://github.com/HKUDS/nanobot/discussions/566) about it!
- **2026-02-11** ‚ú® Enhanced CLI experience and added MiniMax support!

<details>
<summary>Earlier news</summary>

- **2026-02-10** üéâ Released **v0.1.3.post6** with improvements! Check the updates [notes](https://github.com/HKUDS/nanobot/releases/tag/v0.1.3.post6) and our [roadmap](https://github.com/HKUDS/nanobot/discussions/431).
- **2026-02-09** üí¨ Added Slack, Email, and QQ support ‚Äî nanobot now supports multiple chat platforms!
- **2026-02-08** üîß Refactored Providers‚Äîadding a new LLM provider now takes just 2 simple steps! Check [here](#providers).
- **2026-02-07** üöÄ Released **v0.1.3.post5** with Qwen support & several key improvements! Check [here](https://github.com/HKUDS/nanobot/releases/tag/v0.1.3.post5) for details.
- **2026-02-06** ‚ú® Added Moonshot/Kimi provider, Discord integration, and enhanced security hardening!
- **2026-02-05** ‚ú® Added Feishu channel, DeepSeek provider, and enhanced scheduled tasks support!
- **2026-02-04** üöÄ Released **v0.1.3.post4** with multi-provider & Docker support! Check [here](https://github.com/HKUDS/nanobot/releases/tag/v0.1.3.post4) for details.
- **2026-02-03** ‚ö° Integrated vLLM for local LLM support and improved natural language task scheduling!
- **2026-02-02** üéâ nanobot officially launched! Welcome to try üêà nanobot!

</details>

## Key Features of nanobot:

ü™∂ **Ultra-Lightweight**: Just ~4,000 lines of core agent code ‚Äî 99% smaller than Clawdbot.

üî¨ **Research-Ready**: Clean, readable code that's easy to understand, modify, and extend for research.

‚ö°Ô∏è **Lightning Fast**: Minimal footprint means faster startup, lower resource usage, and quicker iterations.

üíé **Easy-to-Use**: One-click to deploy and you're ready to go.

## üèóÔ∏è Architecture

<p align="center">
  <img src="nanobot_arch.png" alt="nanobot architecture" width="800">
</p>

## ‚ú® Features

<table align="center">
  <tr align="center">
    <th><p align="center">üìà 24/7 Real-Time Market Analysis</p></th>
    <th><p align="center">üöÄ Full-Stack Software Engineer</p></th>
    <th><p align="center">üìÖ Smart Daily Routine Manager</p></th>
    <th><p align="center">üìö Personal Knowledge Assistant</p></th>
  </tr>
  <tr>
    <td align="center"><p align="center"><img src="case/search.gif" width="180" height="400"></p></td>
    <td align="center"><p align="center"><img src="case/code.gif" width="180" height="400"></p></td>
    <td align="center"><p align="center"><img src="case/scedule.gif" width="180" height="400"></p></td>
    <td align="center"><p align="center"><img src="case/memory.gif" width="180" height="400"></p></td>
  </tr>
  <tr>
    <td align="center">Discovery ‚Ä¢ Insights ‚Ä¢ Trends</td>
    <td align="center">Develop ‚Ä¢ Deploy ‚Ä¢ Scale</td>
    <td align="center">Schedule ‚Ä¢ Automate ‚Ä¢ Organize</td>
    <td align="center">Learn ‚Ä¢ Memory ‚Ä¢ Reasoning</td>
  </tr>
</table>

## üì¶ Install

**Install from source** (latest features, recommended for development)

```bash
git clone https://github.com/HKUDS/nanobot.git
cd nanobot
pip install -e .
```

**Install with [uv](https://github.com/astral-sh/uv)** (stable, fast)

```bash
uv tool install nanobot-ai
```

**Install from PyPI** (stable)

```bash
pip install nanobot-ai
```

## üöÄ Quick Start

> [!TIP]
> Set your API key in `~/.nanobot/config.json`.
> Get API keys: [OpenRouter](https://openrouter.ai/keys) (Global) ¬∑ [Brave Search](https://brave.com/search/api/) (optional, for web search)

**1. Initialize**

```bash
nanobot onboard
```

**2. Configure** (`~/.nanobot/config.json`)

Add or merge these **two parts** into your config (other options have defaults).

*Set your API key* (e.g. OpenRouter, recommended for global users):
```json
{
  "providers": {
    "openrouter": {
      "apiKey": "sk-or-v1-xxx"
    }
  }
}
```

*Set your model*:
```json
{
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5"
    }
  }
}
```

**3. Chat**

```bash
nanobot agent
```

That's it! You have a working AI assistant in 2 minutes.

## üí¨ Chat Apps

Connect nanobot to your favorite chat platform.

| Channel | What you need |
|---------|---------------|
| **Telegram** | Bot token from @BotFather |
| **Discord** | Bot token + Message Content intent |
| **WhatsApp** | QR code scan |
| **Feishu** | App ID + App Secret |
| **Mochat** | Claw token (auto-setup available) |
| **DingTalk** | App Key + App Secret |
| **Slack** | Bot token + App-Level token |
| **Email** | IMAP/SMTP credentials |
| **QQ** | App ID + App Secret |

<details>
<summary><b>Telegram</b> (Recommended)</summary>

**1. Create a bot**
- Open Telegram, search `@BotFather`
- Send `/newbot`, follow prompts
- Copy the token

**2. Configure**

```json
{
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "YOUR_BOT_TOKEN",
      "allowFrom": ["YOUR_USER_ID"]
    }
  }
}
```

> You can find your **User ID** in Telegram settings. It is shown as `@yourUserId`.
> Copy this value **without the `@` symbol** and paste it into the config file.


**3. Run**

```bash
nanobot gateway
```

</details>

<details>
<summary><b>Mochat (Claw IM)</b></summary>

Uses **Socket.IO WebSocket** by default, with HTTP polling fallback.

**1. Ask nanobot to set up Mochat for you**

Simply send this message to nanobot (replace `xxx@xxx` with your real email):

```
Read https://raw.githubusercontent.com/HKUDS/MoChat/refs/heads/main/skills/nanobot/skill.md and register on MoChat. My Email account is xxx@xxx Bind me as your owner and DM me on MoChat.
```

nanobot will automatically register, configure `~/.nanobot/config.json`, and connect to Mochat.

**2. Restart gateway**

```bash
nanobot gateway
```

That's it ‚Äî nanobot handles the rest!

<br>

<details>
<summary>Manual configuration (advanced)</summary>

If you prefer to configure manually, add the following to `~/.nanobot/config.json`:

> Keep `claw_token` private. It should only be sent in `X-Claw-Token` header to your Mochat API endpoint.

```json
{
  "channels": {
    "mochat": {
      "enabled": true,
      "base_url": "https://mochat.io",
      "socket_url": "https://mochat.io",
      "socket_path": "/socket.io",
      "claw_token": "claw_xxx",
      "agent_user_id": "6982abcdef",
      "sessions": ["*"],
      "panels": ["*"],
      "reply_delay_mode": "non-mention",
      "reply_delay_ms": 120000
    }
  }
}
```



</details>

</details>

<details>
<summary><b>Discord</b></summary>

**1. Create a bot**
- Go to https://discord.com/developers/applications
- Create an application ‚Üí Bot ‚Üí Add Bot
- Copy the bot token

**2. Enable intents**
- In the Bot settings, enable **MESSAGE CONTENT INTENT**
- (Optional) Enable **SERVER MEMBERS INTENT** if you plan to use allow lists based on member data

**3. Get your User ID**
- Discord Settings ‚Üí Advanced ‚Üí enable **Developer Mode**
- Right-click your avatar ‚Üí **Copy User ID**

**4. Configure**

```json
{
  "channels": {
    "discord": {
      "enabled": true,
      "token": "YOUR_BOT_TOKEN",
      "allowFrom": ["YOUR_USER_ID"]
    }
  }
}
```

**5. Invite the bot**
- OAuth2 ‚Üí URL Generator
- Scopes: `bot`
- Bot Permissions: `Send Messages`, `Read Message History`
- Open the generated invite URL and add the bot to your server

**6. Run**

```bash
nanobot gateway
```

</details>

<details>
<summary><b>WhatsApp</b></summary>

Requires **Node.js ‚â•18**.

**1. Link device**

```bash
nanobot channels login
# Scan QR with WhatsApp ‚Üí Settings ‚Üí Linked Devices
```

**2. Configure**

```json
{
  "channels": {
    "whatsapp": {
      "enabled": true,
      "allowFrom": ["+1234567890"]
    }
  }
}
```

**3. Run** (two terminals)

```bash
# Terminal 1
nanobot channels login

# Terminal 2
nanobot gateway
```

</details>

<details>
<summary><b>Feishu (È£û‰π¶)</b></summary>

Uses **WebSocket** long connection ‚Äî no public IP required.

**1. Create a Feishu bot**
- Visit [Feishu Open Platform](https://open.feishu.cn/app)
- Create a new app ‚Üí Enable **Bot** capability
- **Permissions**: Add `im:message` (send messages)
- **Events**: Add `im.message.receive_v1` (receive messages)
  - Select **Long Connection** mode (requires running nanobot first to establish connection)
- Get **App ID** and **App Secret** from "Credentials & Basic Info"
- Publish the app

**2. Configure**

```json
{
  "channels": {
    "feishu": {
      "enabled": true,
      "appId": "cli_xxx",
      "appSecret": "xxx",
      "encryptKey": "",
      "verificationToken": "",
      "allowFrom": []
    }
  }
}
```

> `encryptKey` and `verificationToken` are optional for Long Connection mode.
> `allowFrom`: Leave empty to allow all users, or add `["ou_xxx"]` to restrict access.

**3. Run**

```bash
nanobot gateway
```

> [!TIP]
> Feishu uses WebSocket to receive messages ‚Äî no webhook or public IP needed!

</details>

<details>
<summary><b>QQ (QQÂçïËÅä)</b></summary>

Uses **botpy SDK** with WebSocket ‚Äî no public IP required. Currently supports **private messages only**.

**1. Register & create bot**
- Visit [QQ Open Platform](https://q.qq.com) ‚Üí Register as a developer (personal or enterprise)
- Create a new bot application
- Go to **ÂºÄÂèëËÆæÁΩÆ (Developer Settings)** ‚Üí copy **AppID** and **AppSecret**

**2. Set up sandbox for testing**
- In the bot management console, find **Ê≤ôÁÆ±ÈÖçÁΩÆ (Sandbox Config)**
- Under **Âú®Ê∂àÊÅØÂàóË°®ÈÖçÁΩÆ**, click **Ê∑ªÂä†ÊàêÂëò** and add your own QQ number
- Once added, scan the bot's QR code with mobile QQ ‚Üí open the bot profile ‚Üí tap "ÂèëÊ∂àÊÅØ" to start chatting

**3. Configure**

> - `allowFrom`: Leave empty for public access, or add user openids to restrict. You can find openids in the nanobot logs when a user messages the bot.
> - For production: submit a review in the bot console and publish. See [QQ Bot Docs](https://bot.q.qq.com/wiki/) for the full publishing flow.

```json
{
  "channels": {
    "qq": {
      "enabled": true,
      "appId": "YOUR_APP_ID",
      "secret": "YOUR_APP_SECRET",
      "allowFrom": []
    }
  }
}
```

**4. Run**

```bash
nanobot gateway
```

Now send a message to the bot from QQ ‚Äî it should respond!

</details>

<details>
<summary><b>DingTalk (ÈíâÈíâ)</b></summary>

Uses **Stream Mode** ‚Äî no public IP required.

**1. Create a DingTalk bot**
- Visit [DingTalk Open Platform](https://open-dev.dingtalk.com/)
- Create a new app -> Add **Robot** capability
- **Configuration**:
  - Toggle **Stream Mode** ON
- **Permissions**: Add necessary permissions for sending messages
- Get **AppKey** (Client ID) and **AppSecret** (Client Secret) from "Credentials"
- Publish the app

**2. Configure**

```json
{
  "channels": {
    "dingtalk": {
      "enabled": true,
      "clientId": "YOUR_APP_KEY",
      "clientSecret": "YOUR_APP_SECRET",
      "allowFrom": []
    }
  }
}
```

> `allowFrom`: Leave empty to allow all users, or add `["staffId"]` to restrict access.

**3. Run**

```bash
nanobot gateway
```

</details>

<details>
<summary><b>Slack</b></summary>

Uses **Socket Mode** ‚Äî no public URL required.

**1. Create a Slack app**
- Go to [Slack API](https://api.slack.com/apps) ‚Üí **Create New App** ‚Üí "From scratch"
- Pick a name and select your workspace

**2. Configure the app**
- **Socket Mode**: Toggle ON ‚Üí Generate an **App-Level Token** with `connections:write` scope ‚Üí copy it (`xapp-...`)
- **OAuth & Permissions**: Add bot scopes: `chat:write`, `reactions:write`, `app_mentions:read`
- **Event Subscriptions**: Toggle ON ‚Üí Subscribe to bot events: `message.im`, `message.channels`, `app_mention` ‚Üí Save Changes
- **App Home**: Scroll to **Show Tabs** ‚Üí Enable **Messages Tab** ‚Üí Check **"Allow users to send Slash commands and messages from the messages tab"**
- **Install App**: Click **Install to Workspace** ‚Üí Authorize ‚Üí copy the **Bot Token** (`xoxb-...`)

**3. Configure nanobot**

```json
{
  "channels": {
    "slack": {
      "enabled": true,
      "botToken": "xoxb-...",
      "appToken": "xapp-...",
      "groupPolicy": "mention"
    }
  }
}
```

**4. Run**

```bash
nanobot gateway
```

DM the bot directly or @mention it in a channel ‚Äî it should respond!

> [!TIP]
> - `groupPolicy`: `"mention"` (default ‚Äî respond only when @mentioned), `"open"` (respond to all channel messages), or `"allowlist"` (restrict to specific channels).
> - DM policy defaults to open. Set `"dm": {"enabled": false}` to disable DMs.

</details>

<details>
<summary><b>Email</b></summary>

Give nanobot its own email account. It polls **IMAP** for incoming mail and replies via **SMTP** ‚Äî like a personal email assistant.

**1. Get credentials (Gmail example)**
- Create a dedicated Gmail account for your bot (e.g. `my-nanobot@gmail.com`)
- Enable 2-Step Verification ‚Üí Create an [App Password](https://myaccount.google.com/apppasswords)
- Use this app password for both IMAP and SMTP

**2. Configure**

> - `consentGranted` must be `true` to allow mailbox access. This is a safety gate ‚Äî set `false` to fully disable.
> - `allowFrom`: Leave empty to accept emails from anyone, or restrict to specific senders.
> - `smtpUseTls` and `smtpUseSsl` default to `true` / `false` respectively, which is correct for Gmail (port 587 + STARTTLS). No need to set them explicitly.
> - Set `"autoReplyEnabled": false` if you only want to read/analyze emails without sending automatic replies.

```json
{
  "channels": {
    "email": {
      "enabled": true,
      "consentGranted": true,
      "imapHost": "imap.gmail.com",
      "imapPort": 993,
      "imapUsername": "my-nanobot@gmail.com",
      "imapPassword": "your-app-password",
      "smtpHost": "smtp.gmail.com",
      "smtpPort": 587,
      "smtpUsername": "my-nanobot@gmail.com",
      "smtpPassword": "your-app-password",
      "fromAddress": "my-nanobot@gmail.com",
      "allowFrom": ["your-real-email@gmail.com"]
    }
  }
}
```


**3. Run**

```bash
nanobot gateway
```

</details>

## üåê Agent Social Network

üêà nanobot is capable of linking to the agent social network (agent community). **Just send one message and your nanobot joins automatically!**

| Platform | How to Join (send this message to your bot) |
|----------|-------------|
| [**Moltbook**](https://www.moltbook.com/) | `Read https://moltbook.com/skill.md and follow the instructions to join Moltbook` |
| [**ClawdChat**](https://clawdchat.ai/) | `Read https://clawdchat.ai/skill.md and follow the instructions to join ClawdChat` |

Simply send the command above to your nanobot (via CLI or any chat channel), and it will handle the rest.

## ‚öôÔ∏è Configuration

Config file: `~/.nanobot/config.json`

### Providers

> [!TIP]
> - **Groq** provides free voice transcription via Whisper. If configured, Telegram voice messages will be automatically transcribed.
> - **Zhipu Coding Plan**: If you're on Zhipu's coding plan, set `"apiBase": "https://open.bigmodel.cn/api/coding/paas/v4"` in your zhipu provider config.
> - **MiniMax (Mainland China)**: If your API key is from MiniMax's mainland China platform (minimaxi.com), set `"apiBase": "https://api.minimaxi.com/v1"` in your minimax provider config.
> - **VolcEngine Coding Plan**: If you're on VolcEngine's coding plan, set `"apiBase": "https://ark.cn-beijing.volces.com/api/coding/v3"` in your volcengine provider config.

| Provider | Purpose | Get API Key |
|----------|---------|-------------|
| `custom` | Any OpenAI-compatible endpoint (direct, no LiteLLM) | ‚Äî |
| `openrouter` | LLM (recommended, access to all models) | [openrouter.ai](https://openrouter.ai) |
| `anthropic` | LLM (Claude direct) | [console.anthropic.com](https://console.anthropic.com) |
| `openai` | LLM (GPT direct) | [platform.openai.com](https://platform.openai.com) |
| `deepseek` | LLM (DeepSeek direct) | [platform.deepseek.com](https://platform.deepseek.com) |
| `groq` | LLM + **Voice transcription** (Whisper) | [console.groq.com](https://console.groq.com) |
| `gemini` | LLM (Gemini direct) | [aistudio.google.com](https://aistudio.google.com) |
| `minimax` | LLM (MiniMax direct) | [platform.minimaxi.com](https://platform.minimaxi.com) |
| `aihubmix` | LLM (API gateway, access to all models) | [aihubmix.com](https://aihubmix.com) |
| `siliconflow` | LLM (SiliconFlow/Á°ÖÂü∫ÊµÅÂä®) | [siliconflow.cn](https://siliconflow.cn) |
| `volcengine` | LLM (VolcEngine/ÁÅ´Â±±ÂºïÊìé) | [volcengine.com](https://www.volcengine.com) |
| `dashscope` | LLM (Qwen) | [dashscope.console.aliyun.com](https://dashscope.console.aliyun.com) |
| `moonshot` | LLM (Moonshot/Kimi) | [platform.moonshot.cn](https://platform.moonshot.cn) |
| `zhipu` | LLM (Zhipu GLM) | [open.bigmodel.cn](https://open.bigmodel.cn) |
| `vllm` | LLM (local, any OpenAI-compatible server) | ‚Äî |
| `openai_codex` | LLM (Codex, OAuth) | `nanobot provider login openai-codex` |
| `github_copilot` | LLM (GitHub Copilot, OAuth) | `nanobot provider login github-copilot` |

<details>
<summary><b>OpenAI Codex (OAuth)</b></summary>

Codex uses OAuth instead of API keys. Requires a ChatGPT Plus or Pro account.

**1. Login:**
```bash
nanobot provider login openai-codex
```

**2. Set model** (merge into `~/.nanobot/config.json`):
```json
{
  "agents": {
    "defaults": {
      "model": "openai-codex/gpt-5.1-codex"
    }
  }
}
```

**3. Chat:**
```bash
nanobot agent -m "Hello!"
```

> Docker users: use `docker run -it` for interactive OAuth login.

</details>

<details>
<summary><b>Custom Provider (Any OpenAI-compatible API)</b></summary>

Connects directly to any OpenAI-compatible endpoint ‚Äî LM Studio, llama.cpp, Together AI, Fireworks, Azure OpenAI, or any self-hosted server. Bypasses LiteLLM; model name is passed as-is.

```json
{
  "providers": {
    "custom": {
      "apiKey": "your-api-key",
      "apiBase": "https://api.your-provider.com/v1"
    }
  },
  "agents": {
    "defaults": {
      "model": "your-model-name"
    }
  }
}
```

> For local servers that don't require a key, set `apiKey` to any non-empty string (e.g. `"no-key"`).

</details>

<details>
<summary><b>vLLM (local / OpenAI-compatible)</b></summary>

Run your own model with vLLM or any OpenAI-compatible server, then add to config:

**1. Start the server** (example):
```bash
vllm serve meta-llama/Llama-3.1-8B-Instruct --port 8000
```

**2. Add to config** (partial ‚Äî merge into `~/.nanobot/config.json`):

*Provider (key can be any non-empty string for local):*
```json
{
  "providers": {
    "vllm": {
      "apiKey": "dummy",
      "apiBase": "http://localhost:8000/v1"
    }
  }
}
```

*Model:*
```json
{
  "agents": {
    "defaults": {
      "model": "meta-llama/Llama-3.1-8B-Instruct"
    }
  }
}
```

</details>

<details>
<summary><b>Adding a New Provider (Developer Guide)</b></summary>

nanobot uses a **Provider Registry** (`nanobot/providers/registry.py`) as the single source of truth.
Adding a new provider only takes **2 steps** ‚Äî no if-elif chains to touch.

**Step 1.** Add a `ProviderSpec` entry to `PROVIDERS` in `nanobot/providers/registry.py`:

```python
ProviderSpec(
    name="myprovider",                   # config field name
    keywords=("myprovider", "mymodel"),  # model-name keywords for auto-matching
    env_key="MYPROVIDER_API_KEY",        # env var for LiteLLM
    display_name="My Provider",          # shown in `nanobot status`
    litellm_prefix="myprovider",         # auto-prefix: model ‚Üí myprovider/model
    skip_prefixes=("myprovider/",),      # don't double-prefix
)
```

**Step 2.** Add a field to `ProvidersConfig` in `nanobot/config/schema.py`:

```python
class ProvidersConfig(BaseModel):
    ...
    myprovider: ProviderConfig = ProviderConfig()
```

That's it! Environment variables, model prefixing, config matching, and `nanobot status` display will all work automatically.

**Common `ProviderSpec` options:**

| Field | Description | Example |
|-------|-------------|---------|
| `litellm_prefix` | Auto-prefix model names for LiteLLM | `"dashscope"` ‚Üí `dashscope/qwen-max` |
| `skip_prefixes` | Don't prefix if model already starts with these | `("dashscope/", "openrouter/")` |
| `env_extras` | Additional env vars to set | `(("ZHIPUAI_API_KEY", "{api_key}"),)` |
| `model_overrides` | Per-model parameter overrides | `(("kimi-k2.5", {"temperature": 1.0}),)` |
| `is_gateway` | Can route any model (like OpenRouter) | `True` |
| `detect_by_key_prefix` | Detect gateway by API key prefix | `"sk-or-"` |
| `detect_by_base_keyword` | Detect gateway by API base URL | `"openrouter"` |
| `strip_model_prefix` | Strip existing prefix before re-prefixing | `True` (for AiHubMix) |

</details>


### MCP (Model Context Protocol)

> [!TIP]
> The config format is compatible with Claude Desktop / Cursor. You can copy MCP server configs directly from any MCP server's README.

nanobot supports [MCP](https://modelcontextprotocol.io/) ‚Äî connect external tool servers and use them as native agent tools.

Add MCP servers to your `config.json`:

```json
{
  "tools": {
    "mcpServers": {
      "filesystem": {
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/dir"]
      },
      "my-remote-mcp": {
        "url": "https://example.com/mcp/",
        "headers": {
          "Authorization": "Bearer xxxxx"
        }
      }
    }
  }
}
```

Two transport modes are supported:

| Mode | Config | Example |
|------|--------|---------|
| **Stdio** | `command` + `args` | Local process via `npx` / `uvx` |
| **HTTP** | `url` + `headers` (optional) | Remote endpoint (`https://mcp.example.com/sse`) |

Use `toolTimeout` to override the default 30s per-call timeout for slow servers:

```json
{
  "tools": {
    "mcpServers": {
      "my-slow-server": {
        "url": "https://example.com/mcp/",
        "toolTimeout": 120
      }
    }
  }
}
```

MCP tools are automatically discovered and registered on startup. The LLM can use them alongside built-in tools ‚Äî no extra configuration needed.




### Security

> [!TIP]
> For production deployments, set `"restrictToWorkspace": true` in your config to sandbox the agent.

| Option | Default | Description |
|--------|---------|-------------|
| `tools.exec.enabled` | `true` | When `false`, disables the shell exec tool entirely for both the main agent and all subagents. |
| `tools.restrictToWorkspace` | `false` | When `true`, restricts **all** agent tools (shell, file read/write/edit, list) to the workspace directory. Prevents path traversal and out-of-scope access. |
| `channels.showToolProgress` | `false` | When `true`, sends tool-call progress messages (e.g. `web_search("query")`) to chat channels. Off by default to keep channels clean. |
| `channels.*.allowFrom` | `[]` (allow all) | Whitelist of user IDs. Empty = allow everyone; non-empty = only listed users can interact. |

Example ‚Äî disable shell access:
```json
{
  "tools": {
    "exec": {
      "enabled": false
    }
  }
}
```

### Subagent Profiles

Define named profiles to spawn specialized subagents with different tools, skills, models, and iteration limits.

```json
{
  "agents": {
    "defaults": {
      "subagentMaxIterations": 15
    },
    "subagentProfiles": {
      "researcher": {
        "tools": ["web_search", "web_fetch", "read_file", "list_dir"],
        "skills": ["summarize"],
        "model": "anthropic/claude-haiku-4-5",
        "maxIterations": 10
      },
      "coder": {
        "tools": ["read_file", "write_file", "edit_file", "exec", "list_dir"],
        "skills": ["github"],
        "maxIterations": 25
      }
    }
  }
}
```

| Field | Default | Description |
|-------|---------|-------------|
| `agents.defaults.subagentMaxIterations` | `15` | Default iteration limit for all subagents (overrides the previous hardcoded value). |
| `subagentProfiles.*.tools` | `[]` (all tools) | Tool whitelist. Empty = default set (file ops, exec, web). Available: `read_file`, `write_file`, `edit_file`, `list_dir`, `exec`, `web_search`, `web_fetch`. |
| `subagentProfiles.*.skills` | `[]` | Skills to pre-load into the subagent's system prompt. |
| `subagentProfiles.*.model` | (inherit) | Override the LLM model for this profile. |
| `subagentProfiles.*.maxIterations` | `15` | Override iteration limit for this profile. |

The main agent's `spawn` tool gains an optional `profile` parameter. Spawning without a profile uses the default tool set and the `subagentMaxIterations` setting. The `exec` tool is always gated by `tools.exec.enabled` ‚Äî even if a profile requests it.

### Custom Tools (Plugins)

Drop a `.py` file in `{workspace}/tools/` to add custom tools. Each file is auto-discovered on startup ‚Äî no config changes needed. Plugin tools are available to both the main agent and all subagents automatically.

See [`examples/tools/`](examples/tools/) for ready-to-copy plugin files.

<details>
<summary><b>Quick Start</b></summary>

**1. Create the tools directory:**

```bash
mkdir -p ~/.nanobot/workspace/tools
```

**2. Add a plugin file** (e.g. `~/.nanobot/workspace/tools/greet.py`):

```python
from nanobot.agent.tools import Tool, ToolContext

class GreetTool(Tool):
    def __init__(self, context: ToolContext):
        self._workspace = context.workspace

    @property
    def name(self): return "greet"

    @property
    def description(self): return "Greet someone by name"

    @property
    def parameters(self):
        return {
            "type": "object",
            "properties": {
                "name": {"type": "string", "description": "Who to greet"},
            },
            "required": ["name"],
        }

    async def execute(self, name: str, **kwargs) -> str:
        return f"Hello, {name}!"
```

**3. Restart nanobot** ‚Äî the tool is now available. No config changes needed.

</details>

<details>
<summary><b>Plugin API Reference</b></summary>

Every plugin is a Python class that extends `Tool` (from `nanobot.agent.tools`). You must implement four members:

| Member | Type | Description |
|--------|------|-------------|
| `name` | `property ‚Üí str` | Unique tool name used in LLM function calls (e.g. `"greet"`). Must not collide with built-in tools. |
| `description` | `property ‚Üí str` | One-line description shown to the LLM so it knows when to use the tool. |
| `parameters` | `property ‚Üí dict` | [JSON Schema](https://json-schema.org/) object describing the tool's parameters. Must have `"type": "object"`. |
| `execute(**kwargs) ‚Üí str` | `async method` | Runs the tool. Receives validated keyword arguments matching `parameters`. Must return a string result. |

**Constructor convention:** If your `__init__` accepts a `context` keyword argument, the loader passes a `ToolContext` instance. Otherwise the class is instantiated with no arguments.

**`ToolContext` fields:**

| Field | Type | Description |
|-------|------|-------------|
| `workspace` | `Path` | Absolute path to the nanobot workspace (e.g. `~/.nanobot/workspace`). |
| `allowed_dir` | `Path \| None` | If `restrictToWorkspace` is enabled, this equals `workspace`. Otherwise `None`. Use this to enforce path restrictions in your tool. |
| `working_dir` | `str` | Working directory for command execution (same as `str(workspace)`). |
| `exec_timeout` | `int` | Configured exec timeout in seconds. |
| `restrict_to_workspace` | `bool` | Whether workspace sandboxing is enabled. |
| `brave_api_key` | `str \| None` | Brave Search API key, if configured. |

</details>

<details>
<summary><b>Examples</b></summary>

**Minimal tool (no context needed):**

```python
# ~/.nanobot/workspace/tools/dice.py
import random
from nanobot.agent.tools import Tool

class DiceTool(Tool):
    @property
    def name(self): return "roll_dice"

    @property
    def description(self): return "Roll one or more dice and return the results"

    @property
    def parameters(self):
        return {
            "type": "object",
            "properties": {
                "sides": {"type": "integer", "description": "Number of sides per die", "minimum": 2, "maximum": 100},
                "count": {"type": "integer", "description": "Number of dice to roll", "minimum": 1, "maximum": 20},
            },
            "required": [],
        }

    async def execute(self, sides: int = 6, count: int = 1, **kwargs) -> str:
        rolls = [random.randint(1, sides) for _ in range(count)]
        return f"Rolled {count}d{sides}: {rolls} (total: {sum(rolls)})"
```

**HTTP tool (calls an external API):**

```python
# ~/.nanobot/workspace/tools/weather.py
import httpx
from nanobot.agent.tools import Tool

class WeatherTool(Tool):
    @property
    def name(self): return "weather"

    @property
    def description(self): return "Get current weather for a city using wttr.in"

    @property
    def parameters(self):
        return {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "City name (e.g. 'London', 'New York')"},
            },
            "required": ["city"],
        }

    async def execute(self, city: str, **kwargs) -> str:
        try:
            async with httpx.AsyncClient() as client:
                r = await client.get(
                    f"https://wttr.in/{city}",
                    params={"format": "3"},
                    timeout=10.0,
                )
                r.raise_for_status()
                return r.text.strip()
        except Exception as e:
            return f"Error fetching weather: {e}"
```

**Workspace-aware tool (reads files from workspace):**

```python
# ~/.nanobot/workspace/tools/notes.py
from pathlib import Path
from nanobot.agent.tools import Tool, ToolContext

class SaveNoteTool(Tool):
    def __init__(self, context: ToolContext):
        self._notes_dir = context.workspace / "notes"
        self._notes_dir.mkdir(exist_ok=True)

    @property
    def name(self): return "save_note"

    @property
    def description(self): return "Save a named note to the workspace"

    @property
    def parameters(self):
        return {
            "type": "object",
            "properties": {
                "title": {"type": "string", "description": "Note title (used as filename)"},
                "content": {"type": "string", "description": "Note content"},
            },
            "required": ["title", "content"],
        }

    async def execute(self, title: str, content: str, **kwargs) -> str:
        safe_name = "".join(c if c.isalnum() or c in "-_ " else "_" for c in title)
        path = self._notes_dir / f"{safe_name}.md"
        path.write_text(f"# {title}\n\n{content}\n", encoding="utf-8")
        return f"Note saved to {path}"


class ListNotesTool(Tool):
    def __init__(self, context: ToolContext):
        self._notes_dir = context.workspace / "notes"

    @property
    def name(self): return "list_notes"

    @property
    def description(self): return "List all saved notes"

    @property
    def parameters(self):
        return {"type": "object", "properties": {}, "required": []}

    async def execute(self, **kwargs) -> str:
        if not self._notes_dir.is_dir():
            return "No notes found."
        notes = sorted(self._notes_dir.glob("*.md"))
        if not notes:
            return "No notes found."
        return "\n".join(f"- {n.stem}" for n in notes)
```

> A single file can define multiple `Tool` subclasses. Each is discovered and registered independently.

**Multiple tools in one file** ‚Äî both `save_note` and `list_notes` above are loaded from the same `notes.py`.

</details>

<details>
<summary><b>Using plugin tools in subagent profiles</b></summary>

Plugin tool names work just like built-in tool names in profile configs:

```json
{
  "agents": {
    "subagentProfiles": {
      "researcher": {
        "tools": ["web_search", "web_fetch", "weather", "read_file"],
        "maxIterations": 10
      },
      "note-taker": {
        "tools": ["save_note", "list_notes", "read_file"],
        "skills": ["summarize"]
      }
    }
  }
}
```

When no profile is specified, subagents get **all** available tools (built-in + plugin).

</details>

<details>
<summary><b>Rules & Troubleshooting</b></summary>

**Discovery rules:**
- Only `*.py` files in `{workspace}/tools/` are scanned (not subdirectories)
- Files prefixed with `_` are skipped (e.g. `_helpers.py`) ‚Äî use this for shared utility modules
- Files are processed in alphabetical order; if two files define a tool with the same name, the first one wins
- Built-in tools always take priority over plugins with the same name ‚Äî you cannot override `read_file`, `exec`, etc.

**Error handling:**
- Syntax errors or import failures in a plugin are logged and skipped ‚Äî they won't break the agent
- If a `Tool` subclass fails to instantiate, it is skipped with a warning
- The rest of the plugins and the agent continue normally

**Debugging tips:**
- Run `nanobot agent --logs` to see plugin loading messages
- Look for `Registered plugin tool 'xxx'` in the logs to confirm loading
- Look for `Failed to load plugin xxx` warnings if a tool isn't appearing
- If a tool name collides with a built-in, you'll see `Plugin tool 'xxx' skipped ‚Äî built-in takes priority`

**Built-in tool names** (cannot be overridden): `read_file`, `write_file`, `edit_file`, `list_dir`, `exec`, `web_search`, `web_fetch`, `message`, `spawn`, `cron`

</details>


## CLI Reference

| Command | Description |
|---------|-------------|
| `nanobot onboard` | Initialize config & workspace |
| `nanobot agent -m "..."` | Chat with the agent |
| `nanobot agent` | Interactive chat mode |
| `nanobot agent --no-markdown` | Show plain-text replies |
| `nanobot agent --logs` | Show runtime logs during chat |
| `nanobot gateway` | Start the gateway |
| `nanobot status` | Show status |
| `nanobot provider login openai-codex` | OAuth login for providers |
| `nanobot channels login` | Link WhatsApp (scan QR) |
| `nanobot channels status` | Show channel status |

Interactive mode exits: `exit`, `quit`, `/exit`, `/quit`, `:q`, or `Ctrl+D`.

<details>
<summary><b>Scheduled Tasks (Cron)</b></summary>

```bash
# Add a job
nanobot cron add --name "daily" --message "Good morning!" --cron "0 9 * * *"
nanobot cron add --name "hourly" --message "Check status" --every 3600

# List jobs
nanobot cron list

# Remove a job
nanobot cron remove <job_id>
```

</details>

<details>
<summary><b>Heartbeat (Periodic Tasks)</b></summary>

The gateway wakes up every 30 minutes and checks `HEARTBEAT.md` in your workspace (`~/.nanobot/workspace/HEARTBEAT.md`). If the file has tasks, the agent executes them and delivers results to your most recently active chat channel.

**Setup:** edit `~/.nanobot/workspace/HEARTBEAT.md` (created automatically by `nanobot onboard`):

```markdown
## Periodic Tasks

- [ ] Check weather forecast and send a summary
- [ ] Scan inbox for urgent emails
```

The agent can also manage this file itself ‚Äî ask it to "add a periodic task" and it will update `HEARTBEAT.md` for you.

> **Note:** The gateway must be running (`nanobot gateway`) and you must have chatted with the bot at least once so it knows which channel to deliver to.

</details>

## üê≥ Docker

> [!TIP]
> The `-v ~/.nanobot:/root/.nanobot` flag mounts your local config directory into the container, so your config and workspace persist across container restarts.

### Docker Compose

```bash
docker compose run --rm nanobot-cli onboard   # first-time setup
vim ~/.nanobot/config.json                     # add API keys
docker compose up -d nanobot-gateway           # start gateway
```

```bash
docker compose run --rm nanobot-cli agent -m "Hello!"   # run CLI
docker compose logs -f nanobot-gateway                   # view logs
docker compose down                                      # stop
```

### Docker

```bash
# Build the image
docker build -t nanobot .

# Initialize config (first time only)
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot onboard

# Edit config on host to add API keys
vim ~/.nanobot/config.json

# Run gateway (connects to enabled channels, e.g. Telegram/Discord/Mochat)
docker run -v ~/.nanobot:/root/.nanobot -p 18790:18790 nanobot gateway

# Or run a single command
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot agent -m "Hello!"
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot status
```

## üêß Linux Service

Run the gateway as a systemd user service so it starts automatically and restarts on failure.

**1. Find the nanobot binary path:**

```bash
which nanobot   # e.g. /home/user/.local/bin/nanobot
```

**2. Create the service file** at `~/.config/systemd/user/nanobot-gateway.service` (replace `ExecStart` path if needed):

```ini
[Unit]
Description=Nanobot Gateway
After=network.target

[Service]
Type=simple
ExecStart=%h/.local/bin/nanobot gateway
Restart=always
RestartSec=10
NoNewPrivileges=yes
ProtectSystem=strict
ReadWritePaths=%h

[Install]
WantedBy=default.target
```

**3. Enable and start:**

```bash
systemctl --user daemon-reload
systemctl --user enable --now nanobot-gateway
```

**Common operations:**

```bash
systemctl --user status nanobot-gateway        # check status
systemctl --user restart nanobot-gateway       # restart after config changes
journalctl --user -u nanobot-gateway -f        # follow logs
```

If you edit the `.service` file itself, run `systemctl --user daemon-reload` before restarting.

> **Note:** User services only run while you are logged in. To keep the gateway running after logout, enable lingering:
>
> ```bash
> loginctl enable-linger $USER
> ```

## üìÅ Project Structure

```
nanobot/
‚îú‚îÄ‚îÄ agent/          # üß† Core agent logic
‚îÇ   ‚îú‚îÄ‚îÄ loop.py     #    Agent loop (LLM ‚Üî tool execution)
‚îÇ   ‚îú‚îÄ‚îÄ context.py  #    Prompt builder
‚îÇ   ‚îú‚îÄ‚îÄ memory.py   #    Persistent memory
‚îÇ   ‚îú‚îÄ‚îÄ skills.py   #    Skills loader
‚îÇ   ‚îú‚îÄ‚îÄ subagent.py #    Background task execution
‚îÇ   ‚îî‚îÄ‚îÄ tools/      #    Built-in tools (incl. spawn)
‚îú‚îÄ‚îÄ skills/         # üéØ Bundled skills (github, weather, tmux...)
‚îú‚îÄ‚îÄ channels/       # üì± Chat channel integrations
‚îú‚îÄ‚îÄ bus/            # üöå Message routing
‚îú‚îÄ‚îÄ cron/           # ‚è∞ Scheduled tasks
‚îú‚îÄ‚îÄ heartbeat/      # üíì Proactive wake-up
‚îú‚îÄ‚îÄ providers/      # ü§ñ LLM providers (OpenRouter, etc.)
‚îú‚îÄ‚îÄ session/        # üí¨ Conversation sessions
‚îú‚îÄ‚îÄ config/         # ‚öôÔ∏è Configuration
‚îî‚îÄ‚îÄ cli/            # üñ•Ô∏è Commands
```

## ü§ù Contribute & Roadmap

PRs welcome! The codebase is intentionally small and readable. ü§ó

**Roadmap** ‚Äî Pick an item and [open a PR](https://github.com/HKUDS/nanobot/pulls)!

- [ ] **Multi-modal** ‚Äî See and hear (images, voice, video)
- [ ] **Long-term memory** ‚Äî Never forget important context
- [ ] **Better reasoning** ‚Äî Multi-step planning and reflection
- [ ] **More integrations** ‚Äî Calendar and more
- [ ] **Self-improvement** ‚Äî Learn from feedback and mistakes

### Contributors

<a href="https://github.com/HKUDS/nanobot/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=HKUDS/nanobot&max=100&columns=12&updated=20260210" alt="Contributors" />
</a>


## ‚≠ê Star History

<div align="center">
  <a href="https://star-history.com/#HKUDS/nanobot&Date">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/nanobot&type=Date&theme=dark" />
      <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/nanobot&type=Date" />
      <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/nanobot&type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" />
    </picture>
  </a>
</div>

<p align="center">
  <em> Thanks for visiting ‚ú® nanobot!</em><br><br>
  <img src="https://visitor-badge.laobi.icu/badge?page_id=HKUDS.nanobot&style=for-the-badge&color=00d4ff" alt="Views">
</p>


<p align="center">
  <sub>nanobot is for educational, research, and technical exchange purposes only</sub>
</p>
